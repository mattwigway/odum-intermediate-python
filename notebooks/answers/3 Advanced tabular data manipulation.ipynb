{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed75bac4-7925-446a-8be2-0dda3b1583a0",
   "metadata": {},
   "source": [
    "# Advanced tabular data analysis\n",
    "\n",
    "In the previous notebook, we recapped some of the basic tabular data manipulation tools we covered in Introduction to Python. In this notebook, we'll expand beyond those with some new, more-advanced features of Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69e77f0-69e4-4f80-a889-47176af77c9d",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Import the pandas, numpy, and matplotlib libraries with their usual aliases `pd`, `np`, and `plt`. Load the New York data once again, and perform the same data cleaning steps we did before - merge in the borough names, and rename the Roadway Name column to `roadway_name`, and parse the dates. Put the dataset in a variable named `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8b7e16-ee91-46f3-ba9a-11a3f040125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc3c526-547e-4c39-b447-5657771d0b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/Traffic_Volume_Counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b64e1b-d143-4cbb-864d-2226e65ebc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={\"Roadway Name\": \"roadway_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b20b273-363b-4c5b-9241-ec1381d1e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "borough = pd.read_csv(\"../data/Traffic_Borough.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e3b21-2388-4f25-9024-1957d78dc4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "borough[\"borough\"] = borough.RBoro.replace({\n",
    "    1: \"Manhattan\",\n",
    "    2: \"Bronx\",\n",
    "    3: \"Brooklyn\",\n",
    "    4: \"Queens\",\n",
    "    5: \"Staten Island\"\n",
    "}).astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c608f-f2a8-4dee-9b18-45153c6197a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "borough = borough.drop_duplicates().dropna(subset=\"borough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f947d-8014-487c-b362-fcec693ac069",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(borough, on=\"SegmentID\", how=\"left\", validate=\"m:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3936d285-d765-40e1-98b9-7245598ca585",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Date\"] = pd.to_datetime(data.Date, format=\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64774330-6a74-401b-a5e0-b0a347c8a758",
   "metadata": {},
   "source": [
    "## The index\n",
    "\n",
    "Every `pandas` dataframe has an _index_. This is what is displayed in bold to the left of the data when you display a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9081e0b6-80a7-4948-9fff-3a34704bcef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da2ab1-83f4-4130-8578-d2d876cdf4ad",
   "metadata": {},
   "source": [
    "The _index_ is basically a special column that Pandas uses as the label for each row. When you first read a CSV, the index will always just be sequential numbers. This is used to _align data_ when performing operations. For example, consider something like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665750f5-f540-4cea-b13f-784388838385",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"am_traffic\"] = data[\"7:00-8:00AM\"] + data[\"8:00-9:00AM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a999c-f38f-45ed-b205-9210305ef0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.am_traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c2552-933a-4c53-ac40-e5a00464a843",
   "metadata": {},
   "source": [
    "Pandas knew which values to add up because it matched matching indices. This is true even when the datasets are not in the same order. For example, suppose we sorted the 8-9AM values by total traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db2b9ad-3908-4c48-a4a4-d1c2cef86e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_traffic = data[\"8:00-9:00AM\"].sort_values()\n",
    "data[\"am_traffic_sorted\"] = data[\"7:00-8:00AM\"] + sorted_traffic\n",
    "data.am_traffic_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060b586c-f69e-4ded-b537-ce311037f3a4",
   "metadata": {},
   "source": [
    "This looks like the same result we got before, and it should be - Pandas should have used the index to align the  We can confirm that they're all equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094fe1dc-5fae-452f-a984-39d07a434573",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (data.am_traffic_sorted == data.am_traffic).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8b346-d922-433f-b3cb-e771cf443932",
   "metadata": {},
   "source": [
    "Well, that was not what I expected. Let's look at the ones that are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a619de2c-aada-4d6e-ba13-9bcffb06d1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.am_traffic_sorted != data.am_traffic]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7586ce-78de-4fe6-b005-7952f56bacbb",
   "metadata": {},
   "source": [
    "This is once again missing data causing issues in our analysis. Because many operations can result in NaN, NaN is considered to not equal NaN. For example, dividing by zero results in a NaN, and we wouldn't want code that compared `5 / 0 == 25 / 0` to silently say this was true, even though the data were invalid.\n",
    "\n",
    "In some languages, any comparisons with NaN result in NaN, which usually eventually causes an error. This is not the case with Python. So if you had a function that compared two variables, and both were NaN, it might say they were not equal, and hide that you had missing values in your computation. So in Python, I recommend frequently checking for missing values using the `.isnull()` function.\n",
    "\n",
    "We can rewrite our assertion to check that they are either equal or both NaN. They are. The index alignment worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed0556c-9929-4f40-8d22-9ab952821c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ((data.am_traffic_sorted == data.am_traffic) | (data.am_traffic_sorted.isnull() & data.am_traffic.isnull())).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2ed32-31c6-4423-8cae-c11a64a82e8b",
   "metadata": {},
   "source": [
    "## Meaningful indices\n",
    "\n",
    "By default, Pandas uses a row number as an index. But it is possible to have meaningful indices, as well. For example, there is a `RowID` field in the data. This might be a reference into some other database, or some other identifier used for tracking purposes (it's not, I created it for the purposes of this exercise. But let's ignore that for now.)\n",
    "\n",
    "We can use `.set_index` to set this as the index of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeae3cb-ae78-4808-998d-f3d1a352a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index(\"RowID\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5706df29-16b2-4ef6-bb80-a3a3743f4217",
   "metadata": {},
   "source": [
    "Now, we can use `.loc` to look up items by their index. For instance, let's look up RowID 5512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fadb3a-50cd-4919-bdbe-7681f7221b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[5512]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aaf6b1-bf28-4a55-9353-b0768e7133f4",
   "metadata": {},
   "source": [
    "You can also select multiple row, by enclosing multiple index values in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5feb0e2-6da8-485c-8ca5-8b41ec53af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[[5512, 5518]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a7c7c-839d-4811-9564-e04732f309d4",
   "metadata": {},
   "source": [
    "\"Slicing\" is also a possibility. This uses the `:` operator to specify a range of values. For instance, let's select all rows between 5512 and 5518."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25038221-35a8-4a6b-a398-5089f5af3841",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[5512:5518,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf11dde-7057-480d-ad47-22d0d7d53c78",
   "metadata": {},
   "source": [
    "That might not be what you expect - you might expect 5512:5518 to give you 7 rows, but we got 8,714. But look closely at the first and last row - 5512 and 5518. Pandas has given us all rows in between these rows positionally, not necessarily numerically. We can sort the data frame based on the index, so that positional and numerical ranges are the equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99dfd0c-682e-4678-80c5-a8bae2325aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_index()\n",
    "data.loc[5512:5518,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af5f7e7-de7b-4362-82fa-a8356e42184f",
   "metadata": {},
   "source": [
    "That's more what we might expect. Note that slicing based on a position returns the values for both the start and the end of the range specified.\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Use `.loc` and a slice to select range 2100-2105. Then re-sort the dataframe based on `am_traffic` using the `sort_values` cell below. Note that running your code with the slice now produces a different result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e23a7-3864-4ccf-ab44-63e02e8fc8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[2100:2105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f44d29-a48e-4465-875e-20a92768c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(\"am_traffic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0574cd-29fb-46fe-a1fb-4c666ccdf327",
   "metadata": {},
   "source": [
    "## Selecting rows and columns at the same time\n",
    "\n",
    "By adding a comma to `.loc`, we can select a column or columns as well. If we want to select multiple columns, enclose them in another set of `[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad24da8-5dfa-4a4d-a4ae-ca5e0fb9cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_index()\n",
    "data.loc[5142:5145, \"roadway_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2782fc-275f-4155-a003-757177091498",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[5142:5145, [\"roadway_name\", \"am_traffic\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d676b797-651b-411f-af7b-b84095195259",
   "metadata": {},
   "source": [
    "## Integer / positional indexing\n",
    "\n",
    "`.loc` selects rows or columns based on their index or names. Sometimes, you want to select based on numeric position (often, for example, to extract the first row). `.iloc` indexes data frames based on integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db7977-0ce1-49fa-98d7-17360a1b8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to sort the data frame again to get the index out of order\n",
    "data = data.sort_values(\"am_traffic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948563d-cd69-459e-aaeb-da305323d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f71580-cd8b-451c-95b7-57471cd63b39",
   "metadata": {},
   "source": [
    "Note that we got the third and fourth rows (row indexing starts with 0). You can display the whole data frame to check if you want. Also note that only two rows were returned; when using `.iloc`, the first value of the slice is included (row #2) but the last value is excluded (row #4). This is how slices usually work in Python.\n",
    "\n",
    "A challenge is when you want to select columns and rows using `.iloc`. `.iloc` refers to both by their positions, but generally it's much preferable to refer to columns by name. The following does not work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0314324-a7c9-4b82-a42a-9a97342fdded",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[2:4, \"roadway_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bad51d6-8676-4393-81dd-84355aa012cd",
   "metadata": {},
   "source": [
    "If you are only retrieving values, you can select the rows you want, and then the columns (or vice-versa):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76013f38-9c17-4129-b2ad-a9a053c96d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[2:4][\"roadway_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a49b84-39a8-4ae7-b8d3-50dd7712277f",
   "metadata": {},
   "source": [
    "However, if you are changing the data, you _must not do this_. This is called chained indexing, and it can lead to unexpected results. The problem is that `.iloc[2:4]` may (but does not always) create a copy of that part of the original dataset. If you then change a column value, it may (or may not) only be represented in that copy.\n",
    "\n",
    "When running the code below, you will get a \"setting with copy warning\" which warns of exactly this situation. Note that the roadway names did not change in the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96efb139-a1bd-4bb8-b2de-dac8331f845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[2:4][\"roadway_name\"] = \"TEST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f17b6c-6c49-49e2-a2ba-e2328b0d34f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362655e0-c559-460a-ad7d-cdd1ecc44a9b",
   "metadata": {},
   "source": [
    "The way around this is awkward, but you can use the `.columns.get_loc` function to get the appropriate positional index of a column. That said, needing to combine `iloc` with modifying data is rare; I've only ever had to do it once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6110f0be-d78c-4807-8954-0f362b844f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[2:4, data.columns.get_loc(\"roadway_name\")] = \"TEST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58c7227-ed57-4aee-b6f6-50dfa64325f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d1f26b-6f0b-45f3-bc38-c14592fe880c",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Update the borough for records 2-10 to be Queens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95594f3-05f9-430c-91a3-8bc7ef394cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[2:10, data.columns.get_loc(\"borough\")] = \"Queens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb92680-1ee7-4658-bc5a-4b47e2b4320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84e9699-5c47-43e8-b561-1c15fdde7be6",
   "metadata": {},
   "source": [
    "## Non-unique indices\n",
    "\n",
    "Up until now, we've only used indices where every value was unique. It's possible to use a non-unique index as well. For instance, let's set the SegmentID to be the index. Most segments have multiple observations, so this is non-unique. You'll notice I've added a `.reset_index` call before the call to `set_index`. `reset_index` will convert the existing index back into a column, so we don't lose that information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d1bbb-4c03-4da0-9246-5be5a2ceed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index().set_index(\"SegmentID\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280469aa-8b61-4fda-8baf-6fc359485959",
   "metadata": {},
   "source": [
    "Now, fetching a single index using `.loc` may result in more than one row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb6ea6b-9440-4a03-b447-ed7a363aa1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[35832]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0b30e7-f956-4704-9cb9-6040a9939765",
   "metadata": {},
   "source": [
    "However, it may also result in a single row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e49976-8a39-4b15-a6a8-aaa096812afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[202]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255fc801-e1bc-4e88-8c20-8138e96108ef",
   "metadata": {},
   "source": [
    "Any code you write will have to handle the possibility of getting either a dataframe or a single row when using `.loc`. For this reason, I prefer to avoid non-unique indices. The code below will assert that the index is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76665f87-0e6a-4e5d-a6a2-3e69f6a16409",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not data.index.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fdb01d-2e2f-43c4-8b07-184f89697201",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Set the index to roadway_name, and extract all records from \"EAST 241 STREET\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ca4b2-8938-44b4-8456-344c96e42354",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index().set_index(\"roadway_name\")\n",
    "data.loc[\"EAST 241 STREET\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274ee659-81ab-48f4-9b2b-50142f1b8bf7",
   "metadata": {},
   "source": [
    "## Hierarchical indexing / MultiIndex\n",
    "\n",
    "Pandas also allows multiple columns to be set as the index, which allows for a few additional features. Unique identification of the data in this dataset should be a combination of SegmentID, Direction, and Date. Let's index by all three columns. This requires using a list with set_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d92aa-b826-42c3-8b30-fa5fb33f4457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.reset_index().set_index([\"SegmentID\", \"Direction\", \"Date\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c819711-eeb2-41df-b747-b521744c5389",
   "metadata": {},
   "source": [
    "You can think of the multiindex as being a index where each item is a tuple (SegmentID, Direction, Date). You can select by all or part of this tuple, but you always have to go from left to right - i.e. you can't select by direction unless you also select by SegmentID. When you select a single value from a level in your call to `.loc`, that index level will drop off in the result. For instance, there is no SegmentID when I select only SegmentID 89274."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58997701-5284-43e5-bb94-c618773dd698",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[89274]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fd0f01-be1e-4dc5-9a6a-817393fa7005",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[89274, \"WB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb56068-4ddc-410b-8898-1b83c7d9b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[89274, \"WB\", \"2016-03-02\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe27fdc-0132-4a44-b6c8-b1242bf114d4",
   "metadata": {},
   "source": [
    "### Selecting columns with a multiindex\n",
    "\n",
    "Previously, we used the comma to separate the row indexes from the column indexes. But in the examples above, we used the comma to separate different index levels. To select columns, you need to enclose all of your row selectors in a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12273d6b-5a5f-4c13-a20f-5877684aae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(89274, \"WB\", \"2016-03-02\"), \"roadway_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae91b363-18e0-4336-a1af-869e83157cb0",
   "metadata": {},
   "source": [
    "### Selecting multiple values in a multiindex\n",
    "\n",
    "Like with a regular index, you can select multiple values by enclosing them in a list. Keep in mind that the order matters: a list of tuples selects those exact index values, while a tuple of lists selects any combination of the specified index values. When using a list of tuples, you must include all index levels.\n",
    "\n",
    "When doing anything more complicated that indexing based on a single value at each level like we did above, you should add a `, :` at the end of your call to `.loc` to tell it to select all columns (or, alternately, specify the columns you want to select). Otherwise, `pandas` may misinterpret part of your selection as referring to the columns you want which will either produce an error or give unwanted results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b9228c-519a-4e35-8116-35b1ec3d52cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[[(89274, \"WB\", \"2016-02-27\"), (156485, \"EB\", \"2015-02-07\")], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd8fc91-6fce-49eb-93c4-b8442732b630",
   "metadata": {},
   "source": [
    "You can also use a tuple of lists, which allows any combination of the listed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9461987-0011-4635-8439-1ce54d0688d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[([89274, 156485], [\"EB\", \"WB\"], [\"2016-02-27\", \"2015-02-07\"]), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b0e795-a160-4c95-8509-1b259e662ac8",
   "metadata": {},
   "source": [
    "It is also possible to slice MultiIndexes, but it is very confusing and I wouldn't recommend it. You can read more about that [in the pandas documentation](https://pandas.pydata.org/docs/user_guide/advanced.html#advanced-indexing-with-hierarchical-index). That page also has lots of instructions on using MultiIndexes in general, and it was the source of many of the examples above.\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Select northbound counts only for sensors 88137 and 36705."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d1938-245a-433a-8873-d232fa535606",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[([88137, 36705], \"NB\"), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06462867-eedf-451d-bc25-a9b16ae312da",
   "metadata": {},
   "source": [
    "## Getting rid of the index\n",
    "\n",
    "Sometimes, you may want to get rid of the index you've set, and get back to an index that's just row numbers, 0 through whatever. `.reset_index` will do this. Any columns previously used as part of the index will be converted back into columns (though they may not be in the same order they were before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155424e2-e3e1-4a53-b8ee-87dabf3fa771",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c313e9dd-5e29-4eee-8c50-592f74e93c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5241efa9-022a-4665-8b63-0320b6059a3b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2013f136-be85-4db8-99e6-9c71c53f2b01",
   "metadata": {},
   "source": [
    "## Indexing: Matt's perspective\n",
    "\n",
    "Maybe it's because I was an R user first, but I've never been a big fan of indexing in `pandas`; I find it confusing and prone to create errors (for example, the slicing situation above, where sorting the data changed the results). When I'm selecting data I generally prefer to use the masking syntax we've seen before, and when combining datasets I like to use merge with a common key, rather than relying on indexing. I will occasionally use a meaningful index, perhaps even a hierarchical one, if the selection possibilities are very desirable for a particular problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7105483b-6ace-4473-877c-effc9b016b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
